{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvVRJWWNCWycJsN/dr/ljb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "b8TGzIMs4x8E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load data\n",
        "fake_news = pd.read_csv('Fake.csv')\n",
        "true_news = pd.read_csv('True.csv')"
      ],
      "metadata": {
        "id": "g9Dvjgp348iN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocessing\n",
        "# Adding 'label' column (Fake -> 0, True -> 1)\n",
        "fake_news['label'] = 0\n",
        "true_news['label'] = 1"
      ],
      "metadata": {
        "id": "wooRGbuB5m7d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the two datasets\n",
        "news_data = pd.concat([fake_news, true_news], axis=0)"
      ],
      "metadata": {
        "id": "SAtD13Yo5sOP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns if needed (e.g., subject, date)\n",
        "news_data = news_data[['title', 'text', 'label']]"
      ],
      "metadata": {
        "id": "y9lnFn1i5waP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine title and text columns into a single feature (optional)\n",
        "news_data['combined_text'] = news_data['title'] + \" \" + news_data['text']"
      ],
      "metadata": {
        "id": "qlqs-Lqp5zh2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Text Preprocessing and Vectorization\n",
        "# Use TfidfVectorizer to convert text to numerical features\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
        "X = tfidf.fit_transform(news_data['combined_text'])"
      ],
      "metadata": {
        "id": "ESlwryW255OD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels\n",
        "y = news_data['label']"
      ],
      "metadata": {
        "id": "rRpQbc0z6D7U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "jRM-gA2D6HL3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Model Training and Evaluation\n",
        "\n",
        "# Logistic Regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred_logreg = logreg.predict(X_test)"
      ],
      "metadata": {
        "id": "Pqico4K26Lbt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "N-uiXgKu6Pg0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to print accuracy, confusion matrix, and classification report\n",
        "def evaluate_model(model_name, y_test, y_pred):\n",
        "    print(f\"Evaluation for {model_name}\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
        "    print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "oVqwSVxN9A9H"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Logistic Regression\n",
        "evaluate_model(\"Logistic Regression\", y_test, y_pred_logreg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko0ndjOk9F8Z",
        "outputId": "0dd6c451-7f2f-448e-92b5-b30aa46631fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation for Logistic Regression\n",
            "Accuracy: 0.9858574610244989\n",
            "Confusion Matrix:\n",
            "[[4663   70]\n",
            " [  57 4190]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      4733\n",
            "           1       0.98      0.99      0.99      4247\n",
            "\n",
            "    accuracy                           0.99      8980\n",
            "   macro avg       0.99      0.99      0.99      8980\n",
            "weighted avg       0.99      0.99      0.99      8980\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Random Forest\n",
        "evaluate_model(\"Random Forest\", y_test, y_pred_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCot2C_29KDt",
        "outputId": "c4ff9c2c-1698-4429-b013-43691c11420f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation for Random Forest\n",
            "Accuracy: 0.9907572383073496\n",
            "Confusion Matrix:\n",
            "[[4689   44]\n",
            " [  39 4208]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      4733\n",
            "           1       0.99      0.99      0.99      4247\n",
            "\n",
            "    accuracy                           0.99      8980\n",
            "   macro avg       0.99      0.99      0.99      8980\n",
            "weighted avg       0.99      0.99      0.99      8980\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}